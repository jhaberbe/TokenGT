{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7017f88",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df8c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaberbe/Projects/Personal/TokenGT/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/jhaberbe/Projects/Personal/TokenGT/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\n",
    "    \"/home/jhaberbe/Projects/Personal/TokenGT/data/output-dgi-10-10-20MAY2025.h5ad\"\n",
    ")\n",
    "adata = adata[adata.layers[\"transcript\"].sum(axis=1) > 20].copy()\n",
    "adata.obs[\"log_plin2_area\"] = np.log1p(adata.obs[\"plin2_area\"])\n",
    "adata.obs[\"log_oil_red_o_area\"] = np.log1p(adata.obs[\"oil_red_o_area\"])\n",
    "adata.obs[\"log_lipid_droplet_area\"] = np.log1p(adata.obs[\"lipid_droplet_area\"])\n",
    "\n",
    "adata.X = adata.layers[\"transcript\"].copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3b459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3674434/2419312085.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  adata.obs[\"z_centroid\"] = adata.obs[\"folder\"].replace({\n",
      "/tmp/ipykernel_3674434/2419312085.py:2: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  adata.obs[\"z_centroid\"] = adata.obs[\"folder\"].replace({\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "adata.obs[\"z_centroid\"] = adata.obs[\"folder\"].replace({\n",
    "    k: i * 10_000\n",
    "    for i, k in enumerate(adata.obs[\"folder\"].unique())\n",
    "})\n",
    "\n",
    "ckd_tree = cKDTree(adata.obs[[\"x_centroid\", \"y_centroid\", \"z_centroid\"]])\n",
    "\n",
    "_, neighbor_indicies = ckd_tree.query(adata.obs[[\"x_centroid\", \"y_centroid\", \"z_centroid\"]], k = 31)\n",
    "neighbor_indicies = neighbor_indicies.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47addc",
   "metadata": {},
   "source": [
    "# Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SpatialSingleCellDataSet:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        counts,\n",
    "        log_normalized,\n",
    "        plin2_area,\n",
    "        oil_red_o_area,\n",
    "        lipid_droplet_area,\n",
    "        near_amyloid,\n",
    "        neighbor_indices,\n",
    "        specimen_ids\n",
    "    ):\n",
    "        # Gene Expression Information\n",
    "        self.counts = self._to_tensor(counts, torch.float)\n",
    "        self.log_normalized = self._to_tensor(log_normalized, torch.float)\n",
    "\n",
    "        self.size_factors = (self.counts.sum(axis=1) / self.counts.sum(axis=1).mean()).log()\n",
    "\n",
    "        # Pathology Information\n",
    "        self.plin2_area = self._to_tensor(plin2_area, torch.float)\n",
    "        self.oil_red_o_area = self._to_tensor(oil_red_o_area, torch.float)\n",
    "        self.lipid_droplet_area = self._to_tensor(lipid_droplet_area, torch.float)\n",
    "        self.near_amyloid = self._to_tensor(near_amyloid, torch.float)\n",
    "\n",
    "        # Neighborhood Information\n",
    "        self.specimen_ids = self._to_tensor(specimen_ids, torch.long)\n",
    "        self.neighbor_indices = self._to_tensor(neighbor_indices, torch.long)\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_tensor(x, dtype=torch.float):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().clone().to(dtype)\n",
    "        else:\n",
    "            return torch.tensor(x, dtype=dtype)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.counts.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            # Expression Information\n",
    "            \"counts\": self.counts[idx],\n",
    "            \"log_normalized\": self.log_normalized[idx],\n",
    "            \"size_factors\": self.size_factors[idx],\n",
    "\n",
    "            # Pathology Information\n",
    "            \"plin2_area\": self.plin2_area[idx],\n",
    "            \"oil_red_o_area\": self.oil_red_o_area[idx],\n",
    "            \"lipid_droplet_area\": self.lipid_droplet_area[idx],\n",
    "            \"near_amyloid\": self.near_amyloid[idx],\n",
    "\n",
    "            # Neighborhood Information\n",
    "            \"neighbor_indices\": self.neighbor_indices[idx],\n",
    "\n",
    "            # Cell Metadata\n",
    "            \"specimen_ids\": self.specimen_ids[idx],\n",
    "        }\n",
    "\n",
    "counts = torch.tensor(adata.layers[\"transcript\"])\n",
    "log_normalized = torch.tensor(adata.X)\n",
    "\n",
    "plin2_area = torch.tensor(adata.obs[\"plin2_area\"].values).log1p()\n",
    "oil_red_o_area = torch.tensor(adata.obs[\"oil_red_o_area\"].values).log1p()\n",
    "lipid_droplet_area = torch.tensor(adata.obs[\"lipid_droplet_area\"].values).log1p()\n",
    "near_amyloid = torch.tensor(adata.obs[\"near_amyloid\"].values).float()\n",
    "\n",
    "neighbor_indices = torch.tensor(neighbor_indicies)\n",
    "specimen_ids = torch.tensor(adata.obs[\"folder\"].cat.codes.values)\n",
    "\n",
    "dataset = SpatialSingleCellDataSet(\n",
    "    counts,\n",
    "    log_normalized,\n",
    "    plin2_area,\n",
    "    oil_red_o_area,\n",
    "    lipid_droplet_area,\n",
    "    near_amyloid,\n",
    "    neighbor_indices,\n",
    "    specimen_ids\n",
    ")\n",
    "\n",
    "input_data = dataset[0]\n",
    "\n",
    "dataset[input_data[\"neighbor_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08860981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Gradient Reversal Layer implementation\n",
    "class GradReverse(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)  # Identity forward pass\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_, None\n",
    "\n",
    "def grad_reverse(x, lambda_=1.0):\n",
    "    return GradReverse.apply(x, lambda_)\n",
    "\n",
    "# Variational Encoder (unchanged)\n",
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(hidden_dim, embedding_dim)\n",
    "        self.log_var = nn.Linear(hidden_dim, embedding_dim)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.shared(x)\n",
    "        log_mu = self.mu(h)\n",
    "        log_var = self.log_var(h)\n",
    "        return log_mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b4fd836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spatial Decoder (same as before, you can copy your existing decoder here)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_genes, n_batches):\n",
    "        super().__init__()\n",
    "        self.batch_emb = nn.Embedding(n_batches, embedding_dim)\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.nb_mu = nn.Linear(hidden_dim, n_genes)\n",
    "        self.log_theta = nn.Parameter(torch.zeros(1))\n",
    "        self.hurdle_logits = nn.ModuleDict({\n",
    "            \"plin2\": nn.Linear(hidden_dim, 1),\n",
    "            \"oil_red_o\": nn.Linear(hidden_dim, 1),\n",
    "            \"lipid_droplet\": nn.Linear(hidden_dim, 1)\n",
    "        })\n",
    "        self.hurdle_mu = nn.ModuleDict({\n",
    "            \"plin2\": nn.Linear(hidden_dim, 1),\n",
    "            \"oil_red_o\": nn.Linear(hidden_dim, 1),\n",
    "            \"lipid_droplet\": nn.Linear(hidden_dim, 1)\n",
    "        })\n",
    "        self.hurdle_log_var = nn.ModuleDict({\n",
    "            \"plin2\": nn.Linear(hidden_dim, 1),\n",
    "            \"oil_red_o\": nn.Linear(hidden_dim, 1),\n",
    "            \"lipid_droplet\": nn.Linear(hidden_dim, 1)\n",
    "        })\n",
    "        self.near_amyloid_logit = nn.Linear(hidden_dim, 1)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, z, specimen_ids):\n",
    "        batch_embedding = self.batch_emb(specimen_ids)\n",
    "        h = self.shared(torch.cat([z, batch_embedding], dim=-1))\n",
    "        log_mu_counts = self.nb_mu(h)\n",
    "        log_theta = self.log_theta.expand_as(log_mu_counts)\n",
    "        hurdle_out = {}\n",
    "        for k in self.hurdle_logits.keys():\n",
    "            hurdle_out[k] = {\n",
    "                \"logit_p\": self.hurdle_logits[k](h),\n",
    "                \"mu\": self.hurdle_mu[k](h),\n",
    "                \"log_var\": self.hurdle_log_var[k](h)\n",
    "            }\n",
    "        near_amyloid_logit = self.near_amyloid_logit(h)\n",
    "        return {\n",
    "            \"log_mu_counts\": log_mu_counts,\n",
    "            \"log_theta\": log_theta,\n",
    "            \"hurdle\": hurdle_out,\n",
    "            \"near_amyloid_logit\": near_amyloid_logit\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f0cae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator to predict specimen_ids from latent z\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_batches):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_batches)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25fec77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full VAE with adversarial batch correction\n",
    "class VAEWithAdversarial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim, n_genes, n_batches):\n",
    "        super().__init__()\n",
    "        self.encoder = VariationalEncoder(input_dim, hidden_dim, embedding_dim)\n",
    "        self.decoder = Decoder(embedding_dim, hidden_dim, n_genes, n_batches)\n",
    "        self.discriminator = Discriminator(embedding_dim, hidden_dim // 2, n_batches)\n",
    "\n",
    "    def reparameterize(self, log_mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return log_mu + eps * std\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = input_data[\"log_normalized\"]\n",
    "        specimen_ids = input_data[\"specimen_ids\"]\n",
    "\n",
    "        log_mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(log_mu, log_var)\n",
    "\n",
    "        outputs = self.decoder(z, specimen_ids)\n",
    "        outputs[\"size_factors\"] = input_data[\"size_factors\"]\n",
    "        return outputs, log_mu, log_var, z\n",
    "\n",
    "    def discriminate(self, z, lambda_grl=1.0):\n",
    "        # Apply gradient reversal on z before discriminator\n",
    "        z_rev = grad_reverse(z, lambda_grl)\n",
    "        logits = self.discriminator(z_rev)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f3e9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) Negative Binomial loss for counts\n",
    "\n",
    "def negative_binomial_loss(x, log_mu, log_theta, size_factors):\n",
    "    \"\"\"\n",
    "    x: observed counts (integer tensor)\n",
    "    log_mu: decoded log mean (float tensor)\n",
    "    log_theta: scalar or tensor, shared dispersion (log scale)\n",
    "    size_factors: tensor, log scale size factors (same shape as batch size)\n",
    "    \"\"\"\n",
    "    # Adjust log_mu by adding size factors (log scale)\n",
    "    # size_factors shape: (batch_size,)\n",
    "    # log_mu shape: (batch_size, n_genes)\n",
    "    log_mu_adj = log_mu + size_factors.unsqueeze(-1)  # broadcast size_factors\n",
    "\n",
    "    theta = torch.exp(log_theta)  # dispersion\n",
    "\n",
    "    # logits for NB parameterization: logits = log_mu - log(mu + theta)\n",
    "    logits = log_mu_adj - torch.log(torch.exp(log_mu_adj) + theta)\n",
    "\n",
    "    nb_dist = torch.distributions.NegativeBinomial(total_count=theta, logits=logits)\n",
    "    # Negative log likelihood (sum over genes and batch)\n",
    "    neg_log_likelihood = -nb_dist.log_prob(x).mean()\n",
    "\n",
    "    return neg_log_likelihood\n",
    "\n",
    "\n",
    "# 2) Hurdle normal loss for each pathology feature\n",
    "\n",
    "def hurdle_normal_loss(x, logit_p, mu, log_var):\n",
    "    p = torch.sigmoid(logit_p)\n",
    "    is_zero = (x == 0).float()\n",
    "\n",
    "    bern_loss = -(is_zero * torch.log(1 - p + 1e-8) + (1 - is_zero) * torch.log(p + 1e-8))\n",
    "\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "    const = torch.log(torch.tensor(2 * torch.pi, device=x.device, dtype=x.dtype))\n",
    "    gaussian_nll = 0.5 * ( ((x - mu) / std) ** 2 + 2 * torch.log(std) + const )\n",
    "    gaussian_nll = gaussian_nll * (1 - is_zero)\n",
    "\n",
    "    total_loss = (bern_loss + gaussian_nll).mean()\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# 3) Logistic loss for near_amyloid (binary classification)\n",
    "\n",
    "def near_amyloid_loss(logits, labels):\n",
    "    \"\"\"\n",
    "    logits: raw logits output from decoder (before sigmoid)\n",
    "    labels: binary labels (0/1 float tensor)\n",
    "    \"\"\"\n",
    "    loss = F.binary_cross_entropy_with_logits(logits.squeeze(-1), labels, reduction='sum')\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 4) KL divergence between latent posterior and prior\n",
    "\n",
    "def kl_divergence(log_mu, log_var):\n",
    "    \"\"\"\n",
    "    Standard VAE KL divergence\n",
    "    \"\"\"\n",
    "    kl = -0.5 * torch.sum(1 + log_var - log_mu.pow(2) - log_var.exp())\n",
    "    return kl\n",
    "\n",
    "def discriminator_loss(discriminator_logits, specimen_ids):\n",
    "    \"\"\"\n",
    "    Cross-entropy loss for discriminator predicting specimen_ids.\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(discriminator_logits, specimen_ids)\n",
    "\n",
    "def compute_total_loss(\n",
    "    outputs,\n",
    "    input_data,\n",
    "    log_mu,\n",
    "    log_var,\n",
    "    discriminator_logits=None,\n",
    "    weight_kl=1.0,\n",
    "    weight_nb=1.0,\n",
    "    weight_hurdle=1.0,\n",
    "    weight_amyloid=1.0,\n",
    "    weight_adv=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes total loss for VAE model, optionally including adversarial loss.\n",
    "\n",
    "    If `discriminator_logits` is provided, compute adversarial loss and include weighted in total loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Negative Binomial loss (counts)\n",
    "    nb_loss = negative_binomial_loss(\n",
    "        x=input_data[\"counts\"],\n",
    "        log_mu=outputs[\"log_mu_counts\"],\n",
    "        log_theta=outputs[\"log_theta\"],\n",
    "        size_factors=input_data[\"size_factors\"]\n",
    "    )\n",
    "\n",
    "    # Hurdle normal losses (sum over 3 features)\n",
    "    hurdle_loss = 0.0\n",
    "    for key in [\"plin2\", \"oil_red_o\", \"lipid_droplet\"]:\n",
    "        h = outputs[\"hurdle\"][key]\n",
    "        x = input_data[f\"{key}_area\"]\n",
    "        hurdle_loss += hurdle_normal_loss(x, h[\"logit_p\"], h[\"mu\"], h[\"log_var\"])\n",
    "\n",
    "    # Near amyloid logistic loss\n",
    "    amyloid_loss = near_amyloid_loss(outputs[\"near_amyloid_logit\"], input_data[\"near_amyloid\"])\n",
    "\n",
    "    # KL divergence\n",
    "    kl_loss = kl_divergence(log_mu, log_var)\n",
    "\n",
    "    # Adversarial loss (optional)\n",
    "    if discriminator_logits is not None:\n",
    "        adv_loss = discriminator_loss(discriminator_logits, input_data[\"specimen_ids\"])\n",
    "    else:\n",
    "        adv_loss = torch.tensor(0.0, device=log_mu.device)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = (\n",
    "        weight_nb * nb_loss\n",
    "        + weight_hurdle * hurdle_loss\n",
    "        + weight_amyloid * amyloid_loss\n",
    "        + weight_kl * kl_loss\n",
    "        + weight_adv * adv_loss\n",
    "    )\n",
    "\n",
    "    return total_loss, {\n",
    "        \"total_loss\": total_loss.item(),\n",
    "        \"nb_loss\": nb_loss.item(),\n",
    "        \"hurdle_loss\": hurdle_loss.item(),\n",
    "        \"amyloid_loss\": amyloid_loss.item(),\n",
    "        \"kl_loss\": kl_loss.item(),\n",
    "        \"adv_loss\": adv_loss.item() if isinstance(adv_loss, torch.Tensor) else adv_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "batch_size = 2048\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "\n",
    "vae = VAE(\n",
    "    input_dim=366,\n",
    "    hidden_dim=64,\n",
    "    embedding_dim=16,\n",
    "    n_genes=366,\n",
    "    n_batches=12\n",
    ").to(device)\n",
    "vae.train()\n",
    "\n",
    "discriminator = Discriminator(embedding_dim=16, hidden_dim=32, n_batches=12).to(device)\n",
    "discriminator.train()\n",
    "\n",
    "optimizer_vae = Adam(vae.parameters(), lr=1e-3)\n",
    "optimizer_disc = Adam(discriminator.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "adv_weight = 1.0\n",
    "lambda_grl = 1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, batch_samples in enumerate(data_loader):\n",
    "        # Convert list of dicts to dict of batched tensors and send to device\n",
    "        batch_data = {key: torch.stack([sample[key] for sample in batch_samples]).to(device) for key in batch_samples[0].keys()}\n",
    "\n",
    "        # --- Step 1: Train discriminator ---\n",
    "        optimizer_disc.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            log_mu, log_var = vae.encoder(batch_data[\"log_normalized\"])\n",
    "            z = vae.reparameterize(log_mu, log_var)\n",
    "\n",
    "        disc_logits = discriminator(z.detach())\n",
    "        disc_loss = torch.nn.functional.cross_entropy(disc_logits, batch_data[\"specimen_ids\"])\n",
    "        disc_loss.backward()\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        # --- Step 2: Train VAE ---\n",
    "        optimizer_vae.zero_grad()\n",
    "\n",
    "        log_mu, log_var = vae.encoder(batch_data[\"log_normalized\"])\n",
    "        z = vae.reparameterize(log_mu, log_var)\n",
    "\n",
    "        outputs = vae.decoder(z, batch_data[\"specimen_ids\"])\n",
    "        outputs[\"size_factors\"] = batch_data[\"size_factors\"]\n",
    "\n",
    "        z_rev = grad_reverse(z, lambda_grl)\n",
    "        adv_logits = discriminator(z_rev)\n",
    "\n",
    "        loss, loss_items = compute_total_loss(\n",
    "            outputs=outputs,\n",
    "            input_data=batch_data,\n",
    "            log_mu=log_mu,\n",
    "            log_var=log_var,\n",
    "            discriminator_logits=adv_logits,\n",
    "            weight_adv=adv_weight\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_vae.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}], Loss: {loss.item():.4f}, Disc Loss: {disc_loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "46e0f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_embeddings(model, dataset, batch_size=256, use_mean=True, device=None):\n",
    "    \"\"\"\n",
    "    Extract latent embeddings for all samples in `dataset`.\n",
    "\n",
    "    Args:\n",
    "        model: trained VAE model with encoder\n",
    "        dataset: dataset object (e.g. SpatialSingleCellDataSet)\n",
    "        batch_size: batch size for DataLoader\n",
    "        use_mean: if True, use encoder's mean (log_mu) as embedding,\n",
    "                  else sample from latent distribution\n",
    "        device: torch device (e.g. 'cuda' or 'cpu'), default auto-detect\n",
    "\n",
    "    Returns:\n",
    "        embeddings: Tensor of shape (n_samples, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_samples in loader:\n",
    "            batch_data = {key: torch.stack([sample[key] for sample in batch_samples]).to(device) for key in batch_samples[0].keys()}\n",
    "\n",
    "            log_mu, log_var = model.encoder(batch_data[\"log_normalized\"])\n",
    "\n",
    "            if use_mean:\n",
    "                embeddings = log_mu\n",
    "            else:\n",
    "                std = torch.exp(0.5 * log_var)\n",
    "                eps = torch.randn_like(std)\n",
    "                embeddings = log_mu + eps * std\n",
    "\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "token_embeddings = extract_embeddings(vae, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74205f30",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2178edcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5798, 16])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[::100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "72db3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpatialEmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, neighbor_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: Tensor of shape (n_cells, embedding_dim)\n",
    "            neighbor_indices: LongTensor of shape (n_cells, n_neighbors)\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.neighbor_indices = neighbor_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.embeddings.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            {\n",
    "                \"center\": embedding of center cell (embedding_dim,),\n",
    "                \"neighbors\": embeddings of neighbors (n_neighbors, embedding_dim),\n",
    "                \"center_idx\": index of the center cell\n",
    "            }\n",
    "        \"\"\"\n",
    "        center_embedding = self.embeddings[idx]\n",
    "        neighbor_idxs = self.neighbor_indices[idx]\n",
    "        neighbor_embeddings = self.embeddings[neighbor_idxs]\n",
    "\n",
    "        return {\n",
    "            \"center\": center_embedding,\n",
    "            \"neighbors\": neighbor_embeddings,\n",
    "            \"center_idx\": idx\n",
    "        }\n",
    "\n",
    "spatial_embedding_dataset = SpatialEmbeddingDataset(\n",
    "    embeddings=token_embeddings,\n",
    "    neighbor_indices=neighbor_indices[:, 1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4408b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "\n",
    "def build_simple_flow(embedding_dim, n_transforms=4, hidden_dim=64):\n",
    "    base_dist = StandardNormal([embedding_dim])\n",
    "    transforms = []\n",
    "    for _ in range(n_transforms):\n",
    "        transforms.append(\n",
    "            MaskedAffineAutoregressiveTransform(\n",
    "                features=embedding_dim,\n",
    "                hidden_features=hidden_dim\n",
    "            )\n",
    "        )\n",
    "    # Combine into a proper composite transform\n",
    "    transform = CompositeTransform(transforms)\n",
    "    return Flow(transform, base_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc8e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialTransformerFlow(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_heads=4, n_layers=2, n_neighbors=30):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "        # Learnable CLS token\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "\n",
    "        # Positional encoding (simple learnable)\n",
    "        self.positional_enc = nn.Parameter(torch.randn(1, n_neighbors + 2, embedding_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, nhead=n_heads, dim_feedforward=embedding_dim * 4, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        # Normalizing Flow for predicting next-token embedding\n",
    "        self.flow = build_simple_flow(embedding_dim)\n",
    "\n",
    "    def forward(self, center, neighbors):\n",
    "        \"\"\"\n",
    "        center: (B, embedding_dim)\n",
    "        neighbors: (B, n_neighbors, embedding_dim)\n",
    "        \"\"\"\n",
    "        B = center.size(0)\n",
    "        device = center.device\n",
    "\n",
    "        # Start with [CLS] + center\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, D)\n",
    "        current_seq = torch.cat([cls_tokens, center.unsqueeze(1)], dim=1)\n",
    "\n",
    "        all_log_probs = []\n",
    "\n",
    "        for step in range(neighbors.size(1)):\n",
    "            seq = current_seq + self.positional_enc[:, :current_seq.size(1), :]\n",
    "\n",
    "            h = self.transformer(seq)  # (B, seq_len, D)\n",
    "            context = h[:, -1, :]  # last token representation\n",
    "\n",
    "            # Predict probability of the next token using the flow\n",
    "            next_token = neighbors[:, step, :]\n",
    "            log_prob = self.flow.log_prob(next_token)  # unconditional for now\n",
    "            all_log_probs.append(log_prob)\n",
    "\n",
    "            # Append the ground truth neighbor to the sequence for next step\n",
    "            current_seq = torch.cat([current_seq, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "        all_log_probs = torch.stack(all_log_probs, dim=1)  # (B, n_neighbors)\n",
    "        return all_log_probs\n",
    "\n",
    "def perplexity_loss(log_probs):\n",
    "    \"\"\"\n",
    "    log_probs: (B, n_neighbors), log p(next_token)\n",
    "    Returns: scalar loss (average perplexity)\n",
    "    \"\"\"\n",
    "    nll = -log_probs  # negative log-likelihood per step\n",
    "    entropy = nll.mean()  # average entropy across batch & steps\n",
    "    perplexity = torch.exp(entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec53e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = SpatialTransformerFlow(embedding_dim=token_embeddings.size(1), n_neighbors=30)\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "loader = DataLoader(spatial_embedding_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(loader):\n",
    "        center = batch[\"center\"].to(device)\n",
    "        neighbors = batch[\"neighbors\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(center, neighbors)\n",
    "        loss = perplexity_loss(log_probs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Avg Perplexity = {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea631197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
