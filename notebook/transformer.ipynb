{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f11c0c7",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffe7d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaberbe/Projects/Personal/TokenGT/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/jhaberbe/Projects/Personal/TokenGT/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\n",
    "    \"/home/jhaberbe/Projects/Personal/TokenGT/data/output-dgi-10-10-20MAY2025.h5ad\"\n",
    ")\n",
    "adata = adata[adata.layers[\"transcript\"].sum(axis=1) > 20].copy()\n",
    "adata.obs[\"log_plin2_area\"] = np.log1p(adata.obs[\"plin2_area\"])\n",
    "adata.obs[\"log_oil_red_o_area\"] = np.log1p(adata.obs[\"oil_red_o_area\"])\n",
    "adata.obs[\"log_lipid_droplet_area\"] = np.log1p(adata.obs[\"lipid_droplet_area\"])\n",
    "\n",
    "adata.X = adata.layers[\"transcript\"].copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c769eaf",
   "metadata": {},
   "source": [
    "# My word vomit. \n",
    "\n",
    "I have a dataset, where I have:\n",
    "\n",
    "[near_amyloid, log_plin2_area, log_oil_red_o_area, log_lipid_droplet_area]\n",
    "along with\n",
    "[size-factors precomputed for each sample]\n",
    "[log_normalized count data for F features for each sample]\n",
    "[count data for F features]\n",
    "[specimen each cell belongs to] \n",
    "\n",
    "and I want to have the first part of this model learn to generate embeddings such that we get:\n",
    "NB feature reconstruction for the counts,\n",
    "hurdle log_normal distributions for all pathology metrics.\n",
    "near_amyloid BCE with logits for near_amyloid.\n",
    "I want this to be trained in a fair fashion, meaning I want adversarial training against the specimen information (think like FairGNN). \n",
    "\n",
    "The output at this point should be embeddings generated for all the cells, such that the embeddings fairly distribute specimens across the space.\n",
    "\n",
    "---\n",
    "\n",
    "Jointly, we should train a transformer model that takes in the tokens, and computes perplexity via a set of normalizing flows. We will have neighborhood information, such that we can compute \n",
    "[center cell, neighbor 1, neighbor 2, ..., neighbor 30]\n",
    "We will prepend some kind of [cls] vector to the beginning, and we will incrementally train our model to produce hidden states such that the normalizing flow maximizes the entropy (reduces the suprisal) of the next known token. \n",
    "\n",
    "I imagine it would involve the following type of procedure:\n",
    "provide embedding 1, use the transformer and [cls] to generate a normalizing flow to the embedding space for the next token, get the perplexity of the known token, then add the known token and repeat the procedure until we get to the end. average the perplexities, and use that to train the transformer end. \n",
    "\n",
    "I would further like this to be trained in a fair fashion, meaning that the transformer's learned normalizing flows should also have something like FairGNN (adversarial training against being able to determine the sample the tokens belong to).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328100c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72d9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
